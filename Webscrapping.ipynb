{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
      "     ------------------------------------- 128.2/128.2 kB 19.9 kB/s eta 0:00:00\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.11.1 soupsieve-2.3.2.post1\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml\n",
      "  Downloading lxml-4.9.1-cp310-cp310-win_amd64.whl (3.6 MB)\n",
      "     ---------------------------------------- 3.6/3.6 MB 33.0 kB/s eta 0:00:00\n",
      "Installing collected packages: lxml\n",
      "Successfully installed lxml-4.9.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lxml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.28.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (2022.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write some skills that your not familer with\n",
      "Filtering out java\n",
      "File Saved: 0\n",
      "File Saved: 2\n",
      "File Saved: 3\n",
      "File Saved: 6\n",
      "File Saved: 7\n",
      "File Saved: 9\n",
      "File Saved: 10\n",
      "File Saved: 11\n",
      "File Saved: 12\n",
      "File Saved: 13\n",
      "File Saved: 14\n",
      "File Saved: 15\n",
      "File Saved: 16\n",
      "File Saved: 18\n",
      "File Saved: 20\n",
      "File Saved: 22\n",
      "File Saved: 23\n",
      "Waiting 10 minutes...\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "\n",
    "print(\"Write some skills that your not familer with\")\n",
    "unfamiler_skills = input('>')\n",
    "print(f'Filtering out {unfamiler_skills}')\n",
    "\n",
    "def find_jobs():\n",
    "    html_text = requests.get('https://www.timesjobs.com/candidate/job-search.html?searchType=personalizedSearch&from=submit&txtKeywords=python&txtLocation=').text\n",
    "\n",
    "    #create an instance of beautiful soup\n",
    "    soup = BeautifulSoup(html_text, 'lxml')\n",
    "\n",
    "    jobs = soup.find_all('li', class_ = 'clearfix job-bx wht-shd-bx')\n",
    "    for index, job in enumerate(jobs):\n",
    "        published_date = job.find('span', class_ = 'sim-posted').text\n",
    "        if 'few' in published_date:\n",
    "            company_name = job.find('h3', class_ = 'joblist-comp-name').text.replace(' ', '')\n",
    "            skills = job.find('span', class_ = 'srp-skills').text.replace(' ', '')\n",
    "            more_info = job.header.h2.a['href']\n",
    "            if unfamiler_skills not in skills:\n",
    "                with open(f'posts/{index}.txt', 'w') as f:\n",
    "                    f.write(f\"Company Name: {company_name.strip()}\\n\")\n",
    "                    f.write(f\"Skills: {skills.strip()}\\n\")\n",
    "                    f.write(f\"More Info: {more_info}\")\n",
    "                print(f'File Saved: {index}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    while True:\n",
    "        find_jobs()\n",
    "        time_wait = 10\n",
    "        print(f'Waiting {time_wait} minutes...')\n",
    "        time.sleep(60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df95319d8ce4e1d89f5365ae10992bc1f65da593082b1d264e8f529830ec2f02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
